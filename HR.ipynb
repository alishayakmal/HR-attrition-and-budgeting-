{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alishayakmal/HR-attrition-and-budgeting-/blob/master/HR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfts22G_Nfie",
        "colab_type": "text"
      },
      "source": [
        "# Importing files into Google Colabs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn9JdFMPfPTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#upload the file from running this code (importing the dataset)\n",
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkfREOPmOJ9k",
        "colab_type": "text"
      },
      "source": [
        "# Installing Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZHk_MiVfkD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "29049368-f246-475c-9aa9-5de1482875b6"
      },
      "source": [
        "\n",
        "import pandas as pd   \n",
        "import numpy as np    \n",
        "import io\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_formats = ['retina']\n",
        "import seaborn as sns\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_curve, log_loss\n",
        "SEED = 42\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pylab as pl\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Ignore  the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# data visualisation and manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "#configure\n",
        "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
        "% matplotlib inline  \n",
        "style.use('fivethirtyeight')\n",
        "sns.set(style='whitegrid',color_codes=True)\n",
        "\n",
        "#import the necessary modelling algos.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#preprocess.\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder,OneHotEncoder\n",
        "\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY2_-qQDOghf",
        "colab_type": "text"
      },
      "source": [
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZItdOjHKkb9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Below we are reading the document to see the summary of the data .In this dataset it contains **1470 **rows and **35 **columns. \n",
        "It also shows the average of each column such as average age in the company is **36** with **2.7 rating **for job statisfaction.The least amount of budget spent on  an employee is **1009 **with a minimum  increase of  **3% **in their salary per year.Standhours in this company an employee spent is **80 hours**  per week who  would   remain in the same role for **less than** 8 years. On average employees remain in the company for **7 years **spending **4 years** with the current managers\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW1s0Z4MfuMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "83b2999a-3f08-409f-c27d-e385bafebb1b"
      },
      "source": [
        "\n",
        "HR = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition (1).csv')\n",
        "\n",
        "\n",
        "HR.describe()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-324866cd2706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mHR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'WA_Fn-UseC_-HR-Employee-Attrition (1).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mHR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File WA_Fn-UseC_-HR-Employee-Attrition (1).csv does not exist: 'WA_Fn-UseC_-HR-Employee-Attrition (1).csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbFQxmZ9L8bG",
        "colab_type": "text"
      },
      "source": [
        "There is no missing data and there are 35 attribute in which **74%** are integers and **25%** are object\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFloYJwfLdZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR.isnull().values.any()\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jbsz5s1f9PD",
        "colab_type": "text"
      },
      "source": [
        "**Life Science** are mostly hired , there are **more** male than female .Sales department has the **largest number **of employees in the company"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-PaeM1TQfeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Print all of the object data types and their unique values \n",
        "for column in HR.columns: \n",
        "  if HR[column].dtype == object:\n",
        "     print(str(column) + ':' + str(HR[column].unique()))\n",
        "     print(HR[column].value_counts())\n",
        "     print('_____________________________')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgkIzsc2zv7v",
        "colab_type": "text"
      },
      "source": [
        "Several numerical features are rightly skewed therefore data transformation methods may be required to approach a normal distrubituon prior to fitting a model to the data.\n",
        "\n",
        "This also shows most employees in this company are between **25 and 45 years** old \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taH5LmZnLuj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR.hist(figsize = (20,20),color = 'Purple')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMSs_Z77MuaZ",
        "colab_type": "text"
      },
      "source": [
        "There are total of **1470** employee in which **16%** of them left the company. Below we are going to visualize  different attribute to understand what caused the employees to leave \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iwn9V6OkKHZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(HR.Attrition.value_counts())\n",
        "print(HR.Attrition.value_counts(normalize=True))\n",
        "HR['Attrition'].value_counts().plot(kind= 'bar', color=('Purple','green')).set_title('Attrition')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J51RJvUH2jU4",
        "colab_type": "text"
      },
      "source": [
        "This figure show most employee who leave have a job role in  either **Sales Executives** or **Research Scientist **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7sRp4YR53sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#job role has the most impact on attrition  we can sales attirition has the most job role \n",
        "print(HR.JobRole.value_counts().mean())\n",
        "print(HR.JobRole.value_counts().mean())\n",
        "\n",
        "sns.axes_style('whitegrid')\n",
        "sns.catplot('JobRole', data=HR, aspect=3, kind='count', hue='Attrition', palette=['purple', 'green']).set_ylabels('Number of Employees')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uuQUUauWJ23",
        "colab_type": "text"
      },
      "source": [
        "On average employee who leave the company are between **29 and 31**\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iJlsqEFqT4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplots(figsize =(13,4))\n",
        "sns.countplot(x='Age', hue ='Attrition',data = HR ,palette = ('purple','green'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdmSHJy1FuZ5",
        "colab_type": "text"
      },
      "source": [
        "This shows employee count and standard hours needs to be removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5UO37SOUBUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr=HR.corr()\n",
        "corr=(corr)\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(corr,\n",
        "           xticklabels=corr.columns.values,\n",
        "           yticklabels=corr.columns.values,cmap='Purples')\n",
        "#Monthly income,Job level are dependent upon the TotalWorkingYears\n",
        "#PerformanceRating is highly correlated with PercentSalaryhikeing "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWVdJ0Dm7vxV",
        "colab_type": "text"
      },
      "source": [
        "Dropping irrelavant columns:\n",
        "\n",
        "1) All employees are over18 therefore this column is irrelavant\n",
        "\n",
        "2)Employee numbers are unique identifier hence doesnt have any value \n",
        "\n",
        "3)Standhours in the company for each employee is 80\n",
        "\n",
        "4) Employee count brings doesnt add value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT_H0oJU7uBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR = HR.drop('Over18', axis =1 )\n",
        "HR = HR.drop('EmployeeNumber', axis = 1 )\n",
        "HR = HR.drop('StandardHours',axis =1 )\n",
        "HR = HR.drop('EmployeeCount', axis =1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msItMDXzD84Y",
        "colab_type": "text"
      },
      "source": [
        "This shows the number of years worked decide  the job level of the employees and the monthly income.The higher job level,higher performance rating  then higher the salary increase. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChkQrfN19kgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr=HR.corr()\n",
        "corr=(corr)\n",
        "plt.figure(figsize=(12, 12))\n",
        "sns.heatmap(corr,annot= True,fmt='.0%',\n",
        "           xticklabels=corr.columns.values,\n",
        "           yticklabels=corr.columns.values,cmap='Purples')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSQmLfsH_xhZ",
        "colab_type": "text"
      },
      "source": [
        "Change the catogerical data type into numerical data type \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DePg8cjzOxlv",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBe2CtrzHS-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "for column in HR.columns:\n",
        "   if HR[column].dtype == np.number:\n",
        "    continue \n",
        "   HR[column] = LabelEncoder().fit_transform(HR[column])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM_AqvrYJ1AR",
        "colab_type": "text"
      },
      "source": [
        "Ensure the changes have been made \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRtZKVxAHy-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pFvW-FGJ9lt",
        "colab_type": "text"
      },
      "source": [
        "In order to split data accurately its important to move the attrition column to first column \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmDrukI1J-Js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR['Age_Years'] = HR['Age']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVJOMGcCK5gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR = HR.drop('Age',axis = 1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8EdJocmLWCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSAzl3doPAKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = HR.iloc[:,[0] + list(range(2,31))].values\n",
        "y = HR.iloc[:,1].values\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:,1] = labelencoder_X_1.fit_transform(X[:,1])\n",
        "X[:,3] = labelencoder_X_1.fit_transform(X[:,3])\n",
        "X[:,6] = labelencoder_X_1.fit_transform(X[:,6])\n",
        "X[:,10] = labelencoder_X_1.fit_transform(X[:,10])\n",
        "X[:,14] = labelencoder_X_1.fit_transform(X[:,14])\n",
        "X[:,16] = labelencoder_X_1.fit_transform(X[:,16])\n",
        "X[:,20] = labelencoder_X_1.fit_transform(X[:,20])\n",
        "X[:,21] = labelencoder_X_1.fit_transform(X[:,21])\n",
        "y = labelencoder_X_1.fit_transform(y)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X,y) # Output shown below"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q8_1-6LKWNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_importances=list(model.feature_importances_)\n",
        "indices=sorted(range(len(list_importances)), key=lambda k\n",
        "               :list_importances[k])\n",
        "feature_selected=[None]*34\n",
        "k=0\n",
        "for i in reversed(indices):\n",
        "    if k<=33:\n",
        "        feature_selected[k]=i\n",
        "        k=k+1\n",
        "X_selected = X[:,feature_selected[:18]]\n",
        "l_features=feature_selected\n",
        "i=0\n",
        "for x in feature_selected:\n",
        "    l_features[i] = HR.columns[x]\n",
        "    i=i+1\n",
        "l_features = np.array(l_features)\n",
        "#Extracting 17 most important features among 34 features\n",
        "l_features[:18] #Output shown below"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa18KstLL1wC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = RandomForestClassifier()\n",
        "model.fit(X,y) # Output shown below"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52FKscv8VAc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "rfe = RFE(model, 18)\n",
        "fit = rfe.fit(X, y)\n",
        "print(\"Num Features: %s\" % (fit.n_features_))\n",
        "print(\"Selected Features: %s\" % (fit.support_))\n",
        "print(\"Feature Ranking: %s\" % (fit.ranking_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eF9pxh8WWeG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Selected attributes suggestion : 1)Daily rate  2)Education field 3) Enivornment satisfication\n",
        "4)Hourly Rate  5)Job invovlement , 6Job role , 7)job  statisfcation  8)Monthly income 9) Monthly rate  10) Perecent salary hike 11)Perfomance rating 12)relationshipsatisfaction \n",
        "13)Training time last year 14)yearssincelastpromotion 15)yearsincurrentrole  16)worklifebalance 17) YearswithCur Manager  18)Years at company  19)Stockoptionlevel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d96osqmwWFKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR = HR.drop('Education', axis =1 )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_dGmDK_PSJA",
        "colab_type": "text"
      },
      "source": [
        "# Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiob1DB8VQsb",
        "colab_type": "text"
      },
      "source": [
        "Dropped the following columns :  Education,Employee count ,Over18,EmployeeNumber and StandardHours\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek6yYfTzLmS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = HR.iloc[:,1:HR.shape[1]].values\n",
        "Y = HR.iloc[:,0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23LKnflsL3d2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split the data into 80% training and 20% testing \n",
        "\n",
        "X_train ,X_test,Y_train , Y_test = train_test_split(X,Y , test_size = 0.20 , random_state = 40 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-iptsnAU4kW",
        "colab_type": "text"
      },
      "source": [
        "**Using Random forest Classifier** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoWUC3xsMyQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "forest = RandomForestClassifier(n_estimators = 10 , criterion = 'entropy', random_state = 0)\n",
        "forest.fit(X_train, Y_train )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-ObX75gpb5t",
        "colab_type": "text"
      },
      "source": [
        "**This shows the accuracy of model is 86% **\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vHlf46pNvi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show the confusion matrix and accuracy score for the model on the test data\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "cm = confusion_matrix(Y_test,forest.predict(X_test))\n",
        "\n",
        "TN = cm[0][0]\n",
        "TP = cm[1][1]\n",
        "FN = cm[1][0]\n",
        "FP = cm[0][1]\n",
        "\n",
        "\n",
        "print(cm)\n",
        "\n",
        "print('Model Testing Accuracy = {}'.format((TP + TN)/(TP + TN + FN +FP)))\n",
        "\n",
        "sn.heatmap(cm, annot=True)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hcRzmzIs-_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "predictions=forest.predict(X_test)\n",
        "print(classification_report(Y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfBISTVNW884",
        "colab_type": "text"
      },
      "source": [
        "**Using Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prBwuh1AC0vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = HR.iloc[:,1:HR.shape[1]].values\n",
        "Y = HR.iloc[:,0].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                   test_size=0.20, random_state= 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU7rQLJDRI3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = LogisticRegression(class_weight=\"balanced\")\n",
        "\n",
        "#Training the Model\n",
        "clf_trained = clf.fit(X_train, Y_train) #Output shown below\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMZN0AV4TjGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_trained.score(X_train,Y_train) # Output shown below"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zGxAAhSTWJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_trained.score(X_test,Y_test) # Output shown below"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK5uD6U4Dz_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=clf_trained.predict(X_test)\n",
        "print(classification_report(Y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMWnIacp_rEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "cm = confusion_matrix(Y_test,clf_trained.predict(X_test))\n",
        "\n",
        "TN = cm[0][0]\n",
        "TP = cm[1][1]\n",
        "FN = cm[1][0]\n",
        "FP = cm[0][1]\n",
        "\n",
        "\n",
        "print(cm)\n",
        "\n",
        "print('Model Testing Accuracy = {}'.format((TP + TN)/(TP + TN + FN +FP)))\n",
        "\n",
        "sn.heatmap(cm, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvis63lQifw6",
        "colab_type": "text"
      },
      "source": [
        "KNNeighborsClassifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_P-h77bg4Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split( \n",
        "    X, y, test_size = 0.25, random_state = 40) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktPIkglbg4o1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "neighbors = [] \n",
        "cv_scores = [] \n",
        "\t\n",
        "from sklearn.model_selection import cross_val_score \n",
        "# perform 10 fold cross validation \n",
        "for k in range(1, 40, 2): \n",
        "\tneighbors.append(k) \n",
        "\tknn = KNeighborsClassifier(n_neighbors = k) \n",
        "\tscores = cross_val_score( \n",
        "\t\tknn, X_train, y_train, cv = 10, scoring = 'accuracy') \n",
        "\tcv_scores.append(scores.mean()) \n",
        "error_rate = [1-x for x in cv_scores] \n",
        "\t\n",
        "# determining the best k \n",
        "optimal_k = neighbors[error_rate.index(min(error_rate))] \n",
        "print('The optimal number of neighbors is % d ' % optimal_k) \n",
        "\t\n",
        "# plot misclassification error versus k \n",
        "plt.figure(figsize = (10, 6)) \n",
        "plt.plot(range(1, 40, 2), error_rate, color ='green', linestyle ='dashed', marker ='o', \n",
        "\t\tmarkerfacecolor ='purple', markersize = 10) \n",
        "plt.xlabel('Number of neighbors') \n",
        "plt.ylabel('Misclassification Error') \n",
        "plt.show() \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DodMT9Asg7Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict, cross_val_score \n",
        "from sklearn.metrics import accuracy_score, classification_report \n",
        "from sklearn.metrics import confusion_matrix \n",
        "\n",
        "def print_score(clf, X_train, y_train, X_test, y_test, train = True): \n",
        "\tif train: \n",
        "\t\tprint(\"Train Result:\") \n",
        "\t\tprint(\"------------\") \n",
        "\t\tprint(\"Classification Report: \\n {}\\n\".format(classification_report( \n",
        "\t\t\t\ty_train, clf.predict(X_train)))) \n",
        "\t\tprint(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix( \n",
        "\t\t\t\ty_train, clf.predict(X_train)))) \n",
        "\n",
        "\t\tres = cross_val_score(clf, X_train, y_train, \n",
        "\t\t\t\t\t\t\tcv = 10, scoring ='accuracy') \n",
        "\t\tprint(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res))) \n",
        "\t\tprint(\"Accuracy SD: \\t\\t {0:.4f}\".format(np.std(res))) \n",
        "\t\tprint(\"accuracy score: {0:.4f}\\n\".format(accuracy_score( \n",
        "\t\t\t\ty_train, clf.predict(X_train)))) \n",
        "\t\tprint(\"----------------------------------------------------------\") \n",
        "\t\t\t\t\n",
        "\telif train == False: \n",
        "\t\tprint(\"Test Result:\") \n",
        "\t\tprint(\"-----------\") \n",
        "\t\tprint(\"Classification Report: \\n {}\\n\".format( \n",
        "\t\t\t\tclassification_report(y_test, clf.predict(X_test)))) \n",
        "\t\tprint(\"Confusion Matrix: \\n {}\\n\".format( \n",
        "\t\t\t\tconfusion_matrix(y_test, clf.predict(X_test)))) \n",
        "\t\tprint(\"accuracy score: {0:.4f}\\n\".format( \n",
        "\t\t\t\taccuracy_score(y_test, clf.predict(X_test)))) \n",
        "\t\tprint(\"-----------------------------------------------------------\") \n",
        "\t\t\n",
        "knn = KNeighborsClassifier(n_neighbors = 7) \n",
        "knn.fit(X_train, y_train) \n",
        "print_score(knn, X_train, y_train, X_test, y_test, train = True) \n",
        "print_score(knn, X_train, y_train, X_test, y_test, train = False) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuAl58tXXgi1",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64B_fX_vX1rx",
        "colab_type": "text"
      },
      "source": [
        "Spliting the data for testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdi-yAZ8AEFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = HR.iloc[:,1:HR.shape[1]].values\n",
        "Y = HR.iloc[:,0].values\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
        "                                   test_size=0.20, random_state= 40)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2lYuNlSXqxU",
        "colab_type": "text"
      },
      "source": [
        "As the dataset imbalance in order to get higher accurate SMOTE is used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXYNJemeP5Ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oversampler=SMOTE(random_state=42)\n",
        "x_train_smote,  y_train_smote = oversampler.fit_sample(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG09ynkeQH3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare(model):\n",
        "    clf=model\n",
        "    clf.fit(x_train_smote,y_train_smote)\n",
        "    pred=clf.predict(X_test)\n",
        "    \n",
        "    # Calculating various metrics\n",
        "    \n",
        "    acc.append(accuracy_score(pred,Y_test))\n",
        "    prec.append(precision_score(pred,Y_test))\n",
        "    rec.append(recall_score(pred,Y_test))\n",
        "    auroc.append(roc_auc_score(pred,Y_test))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buVFjpl2YCAy",
        "colab_type": "text"
      },
      "source": [
        "Comparing models to see which perform well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvtc6cDuQPPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=[]\n",
        "prec=[]\n",
        "rec=[]\n",
        "auroc=[]\n",
        "models=[SVC(kernel='rbf'),RandomForestClassifier(),GradientBoostingClassifier(),AdaBoostClassifier(),KNeighborsClassifier(),GaussianProcessClassifier(), MLPClassifier(),QuadraticDiscriminantAnalysis(),XGBClassifier()\n",
        "]\n",
        "model_names=['rbfSVM','RandomForestClassifier','GradientBoostingClassifier','AdaBoostClassifier','KNeighborsClassifier','GaussianProcessClassifier', 'MLPClassifier','QuadraticDiscriminantAnalysis','XGBClassifier']\n",
        "\n",
        "for model in range(len(models)):\n",
        "    compare(models[model])\n",
        "    \n",
        "d={'Modelling Algo':model_names,'Accuracy':acc,'Precision':prec,'Recall':rec,'Area Under ROC Curve':auroc}\n",
        "met_df=pd.DataFrame(d)\n",
        "met_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5_2zatqDPCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comp_models(met_df,metric):\n",
        "    sns.set_palette(\"cool\")   \n",
        "    sns.factorplot(data=met_df,x=metric,y='Modelling Algo',size=5,aspect=2,kind='bar')\n",
        "    sns.factorplot(data=met_df,y=metric,x='Modelling Algo',size=10,aspect=2,kind='point')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cNbQqCRDbHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp_models(met_df,'Accuracy')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p13cxGylDxOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp_models(met_df,'Precision')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR3YrSRmDzhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp_models(met_df,'Recall')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2ytB7OysnpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp_models(met_df,'Area Under ROC Curve')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWrumWG3F3xt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FtUEXt2GLEf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6eFIpHMGL-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st.write(\"\"\"\n",
        "# HR Prediction App\n",
        "This app predicts the **HR** type!\n",
        "\"\"\")\n",
        "\n",
        "st.sidebar.header('User Input Parameters')\n",
        "\n",
        "def user_input_features():\n",
        "    Department = st.sidebar.slider('Department','Life Science','HR','Research')\n",
        "    Perfomance_rating  = st.sidebar.slider('Performance', 1,2,3,4)\n",
        "    Enivronment = st.sidebar.slider('Petal length', 1,2,3,4)\n",
        "    MonthlyIncome = st.sidebar.slider('Petal width', 500, 5000, 10000,100000)\n",
        "    data = {HR}\n",
        "    features = pd.DataFrame(data, index=[0])\n",
        "    return features\n",
        "\n",
        "HR = user_input_features()\n",
        "\n",
        "st.subheader('User Input parameters')\n",
        "st.write(HR)\n",
        "\n",
        " \n",
        "X = HR.data\n",
        "Y = HR.target\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X, Y)\n",
        "\n",
        "prediction = clf.predict(HR)\n",
        "prediction_proba = clf.predict_proba(HR)\n",
        "\n",
        "st.subheader('Class labels and their corresponding index number')\n",
        "st.write(iris.target_names)\n",
        "\n",
        "st.subheader('Prediction')\n",
        "st.write(iris.target_names[prediction])\n",
        "#st.write(prediction)\n",
        "\n",
        "st.subheader('Prediction Probability')\n",
        "st.write(prediction_proba)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}